{
 "cells": [
  {
   "cell_type": "raw",
   "id": "474ab303-1d07-49a3-9315-05a3eeb5f9f9",
   "metadata": {},
   "source": [
    "CIFAR-10 CNN Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0ad22a-bbbe-4752-9afd-adbcb97de8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb95772c-2eb7-450c-8cee-725c652c164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2c1adf-c716-4bef-a75b-83de1abeb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a7909d-9a5b-4d65-b41e-1f20e4b2f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aab9e3d-6d53-41df-ac9c-f9c1e093644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 32, 16, 16]           4,640\n",
      "         MaxPool2d-4             [-1, 32, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          18,496\n",
      "         MaxPool2d-6             [-1, 64, 4, 4]               0\n",
      "            Linear-7                  [-1, 128]         131,200\n",
      "            Linear-8                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 156,074\n",
      "Trainable params: 156,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.27\n",
      "Params size (MB): 0.60\n",
      "Estimated Total Size (MB): 0.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SmallCNN().to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58174860-0b65-450a-81b5-56ce37d36ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4841\n",
      "Epoch 2, Loss: 1.1088\n",
      "Epoch 3, Loss: 0.9362\n",
      "Epoch 4, Loss: 0.8256\n",
      "Epoch 5, Loss: 0.7436\n",
      "Epoch 6, Loss: 0.6748\n",
      "Epoch 7, Loss: 0.6173\n",
      "Epoch 8, Loss: 0.5653\n",
      "Epoch 9, Loss: 0.5167\n",
      "Epoch 10, Loss: 0.4669\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc413e1a-36ea-4a21-bcbe-4e8a7d8f5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.97%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b316f7fc-d80c-4012-a634-70fbd265459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a071aa6-8def-4087-9261-3c4307422912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Quantized] Test Accuracy: 73.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_cpu_model(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"[Quantized] Test Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "evaluate_cpu_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a18312f-a0ce-4627-9788-b43590d21388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.63 MB\n",
      "Model size: 0.23 MB\n",
      "Avg inference time on cpu: 0.82 ms\n",
      "Avg inference time on cpu: 0.65 ms\n"
     ]
    }
   ],
   "source": [
    "def model_size(model, name=\"model.pth\"):\n",
    "    torch.save(model.state_dict(), name)\n",
    "    size = os.path.getsize(name) / 1e6\n",
    "    print(f\"Model size: {size:.2f} MB\")\n",
    "\n",
    "model_size(model, \"model_fp32.pth\")\n",
    "model_size(quantized_model, \"model_int8.pth\")\n",
    "\n",
    "# Inference Timer\n",
    "def measure_inference_time(model, device='cpu', n_runs=100):\n",
    "    dummy = torch.randn(1, 3, 32, 32).to(device)\n",
    "    model.eval()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_runs):\n",
    "            model(dummy)\n",
    "    end = time.time()\n",
    "    avg_time = (end - start) / n_runs * 1000\n",
    "    print(f\"Avg inference time on {device}: {avg_time:.2f} ms\")\n",
    "\n",
    "measure_inference_time(model, 'cpu')\n",
    "measure_inference_time(quantized_model, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "279489e1-ac0d-4521-9bac-8c75a60c5dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scripted model saved for edge deployment.\n"
     ]
    }
   ],
   "source": [
    "scripted_model = torch.jit.script(quantized_model)\n",
    "scripted_model.save(\"cifar10_quantized_scripted.pt\")\n",
    "print(\"Scripted model saved for edge deployment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164f65e8-bd62-4f8f-a9e8-d9b1c7ed15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model exported to 'cifar10_model.onnx'\n"
     ]
    }
   ],
   "source": [
    "onnx_input = torch.randn(1, 3, 32, 32)\n",
    "torch.onnx.export(\n",
    "    model,                        # original model (float32)\n",
    "    onnx_input,                   # example input tensor\n",
    "    \"cifar10_model.onnx\",        # output file name\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "print(\"ONNX model exported to 'cifar10_model.onnx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1c291-4dc0-4954-b4d5-85af4bcf368f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(myenv-GPU)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
